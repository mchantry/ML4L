{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3228247-5b3b-400a-9dd1-774191a65374",
   "metadata": {},
   "source": [
    "### Noise calculations for paper revisions\n",
    "\n",
    "\n",
    "This notebook explores the model training noise as requested during the first round of paper review.\n",
    "\n",
    "We use the conda environment `analysis`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2cfad8-1557-4dfe-8ad6-827ce241442f",
   "metadata": {},
   "source": [
    "#### Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c53878c2-88a6-4bf3-8c0f-d5708faa6597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None #Ignore SettingWithCopyWarning - we are safe here\n",
    "\n",
    "def load_predictions(path):\n",
    "\n",
    "    df = pd.read_parquet(path+'predictions.parquet')\n",
    "    \n",
    "    \n",
    "    #Calculate some extra columns\n",
    "    df['model_predicion_bias'] = df.MODIS_LST - df.predictions\n",
    "    df['model_predicion_error'] = df.MODIS_LST - df.predictions\n",
    "        \n",
    "    df['ERA_predicion_bias'] = df.MODIS_LST - df.skt_unnormalised\n",
    "    df['ERA_predicion_error'] = abs(df.MODIS_LST - df.skt_unnormalised)\n",
    "\n",
    "\n",
    "    print ('----------------------------------MODEL-------------------------------------------------')\n",
    "    print(\"Mean/Median/Std prediction bias:\", df['model_predicion_bias'].mean(), df['model_predicion_bias'].median(),df['model_predicion_bias'].std())\n",
    "    print(\"Mean/Median/Std prediction error:\", df['model_predicion_error'].mean(), df['model_predicion_error'].median(),df['model_predicion_error'].std())\n",
    "\n",
    "    \n",
    "    #Average predictions and errors over the year\n",
    "    df_grouped = df.groupby(['latitude_ERA', 'longitude_ERA'],as_index=False).mean() \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return df,df_grouped\n",
    "\n",
    "\n",
    "\n",
    "def surface_noise_numbers(df):\n",
    "    \n",
    " \n",
    "    \n",
    "    print(\"Numer of grid points:\", len(df))\n",
    "    print(\"Median variance:\", df['variance'].median())\n",
    "    print(\"Mean variance:\", df['variance'].mean())\n",
    "    \n",
    "    print(\"Median median error:\", df['median_error'].median())\n",
    "    print(\"Mean mean error:\", df['mean_error'].mean())\n",
    "    \n",
    "  \n",
    "\n",
    "    return df['variance'].median()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def pipeline(models_to_compare,ID):\n",
    "    \n",
    "    annually_averaged_dfs = []\n",
    "    for m in models_to_compare:\n",
    "        predictions,predictions_averaged = load_predictions(m)\n",
    "        annually_averaged_dfs.extend([predictions_averaged])\n",
    "        \n",
    "        \n",
    "        \n",
    "    change_in_fields = pd.read_pickle('tmp_data/change_in_fields.pkl')\n",
    "    change_in_fields['latitude_join'] = round(change_in_fields.latitude_ERA,3)\n",
    "    change_in_fields['longitude_join'] = round(change_in_fields.longitude_ERA,3) #just used for joining due to loss of precision from Margs file\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Create a new df that will just hold the differences   \n",
    "\n",
    "    df =annually_averaged_dfs[0] #pick a df to get latitudes \n",
    "    data = { 'latitude_ERA':     df.latitude_ERA, \n",
    "             'longitude_ERA':    df.longitude_ERA,\n",
    "             'MODIS_LST':        df.MODIS_LST,\n",
    "             'latitude_join':    round(df.latitude_ERA,3), \n",
    "             'longitude_join':    round(df.longitude_ERA,3)}\n",
    "\n",
    "\n",
    "    i = 1\n",
    "    selected_cols = [] #we will use this later when computing variances\n",
    "    for df in annually_averaged_dfs:\n",
    "        data[f'prediction_error_{i}'] = df['model_predicion_error']\n",
    "        data[f'prediction_{i}'] = df['predictions']\n",
    "\n",
    "        selected_cols.extend([f'prediction_error_{i}'])\n",
    "        i = i+1\n",
    "\n",
    "    df_new = pd.DataFrame(data)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Join and save\n",
    "    df_cat = pd.merge(df_new,change_in_fields,how='inner',on=['latitude_join', 'longitude_join'],suffixes=('', '_y')) #inner join.\n",
    "    df_cat = df_cat.drop(['latitude_join', 'longitude_join','latitude_ERA_y', 'longitude_ERA_y'], axis=1) #Get rid of junk columns\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    df_cat['median_error']=df_cat[selected_cols].median(axis=1) # median over the prediciton errors for each grid point\n",
    "    df_cat['mean_error']  =df_cat[selected_cols].mean(axis=1)     # mean over the prediciton errors for each grid point\n",
    "    df_cat['variance']    =df_cat[selected_cols].std(axis=1)        # variance over the prediciton errors for each grid point i.e. noise\n",
    "    \n",
    "    df_cat['label'] = ID\n",
    "    return df_cat\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b8cc222-c8ef-4b23-8a34-3b13d346cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2ec5b98-0e78-4c74-96f9-a9d4e0b2889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/network/group/aopp/predict/TIP016_PAXTON_RPSPEEDY/ML4L/ECMWF_files/raw/processed_data/trained_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03fa7099-c571-4e36-9b81-a331803946a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #ignore FutureWarning statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7871624-2f89-4111-95b0-5691140881ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------MODEL-------------------------------------------------\n",
      "Mean/Median/Std prediction bias: 0.08259364 0.226959228515625 3.8190529346466064\n",
      "Mean/Median/Std prediction error: 0.08259364 0.226959228515625 3.8190529346466064\n",
      "----------------------------------MODEL-------------------------------------------------\n",
      "Mean/Median/Std prediction bias: 0.17329945 0.29364013671875 3.8254127502441406\n",
      "Mean/Median/Std prediction error: 0.17329945 0.29364013671875 3.8254127502441406\n",
      "----------------------------------MODEL-------------------------------------------------\n",
      "Mean/Median/Std prediction bias: 0.0777295 0.20306396484375 3.8673462867736816\n",
      "Mean/Median/Std prediction error: 0.0777295 0.20306396484375 3.8673462867736816\n",
      "----------------------------------MODEL-------------------------------------------------\n",
      "Mean/Median/Std prediction bias: 0.06500694 0.195526123046875 3.8166935443878174\n",
      "Mean/Median/Std prediction error: 0.06500694 0.195526123046875 3.8166935443878174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#V15\n",
    "model_1 = f'{root}V15_noise_expt_1/'\n",
    "model_2 = f'{root}V15_noise_expt_2/'\n",
    "model_3 = f'{root}V15_noise_expt_3/'\n",
    "model_4 = f'{root}V15_noise_expt_4/'\n",
    "models_to_compare = [model_1,model_2, model_3,model_4]\n",
    "df_V15 = pipeline(models_to_compare,'V15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af9aa8-6e8b-42d0-86c2-c7d1dab3523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#V20\n",
    "model_1 = f'{root}V20_noise_expt_1/'\n",
    "model_2 = f'{root}V20_noise_expt_2/'\n",
    "model_3 = f'{root}V20_noise_expt_3/'\n",
    "model_4 = f'{root}V20_noise_expt_4/'\n",
    "models_to_compare = [model_1,model_2, model_3,model_4]\n",
    "df_V20 = pipeline(models_to_compare,'V20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765e162-97a7-49fb-a2d2-d5789bd88832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V15X\n",
    "model_1 = f'{root}V15X_noise_expt_1/'\n",
    "model_2 = f'{root}V15X_noise_expt_2/'\n",
    "model_3 = f'{root}V15X_noise_expt_3/'\n",
    "model_4 = f'{root}V15X_noise_expt_4/'\n",
    "models_to_compare = [model_1,model_2, model_3,model_4]\n",
    "df_V15X = pipeline(models_to_compare,'V15X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999af6cb-4ec2-4264-b604-4e7af90041e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V20X\n",
    "model_1 = f'{root}V20X_noise_expt_1/'\n",
    "model_2 = f'{root}V20X_noise_expt_2/'\n",
    "model_3 = f'{root}V20X_noise_expt_3/'\n",
    "model_4 = f'{root}V20X_noise_expt_4/'\n",
    "models_to_compare = [model_1,model_2, model_3,model_4]\n",
    "df_V20X = pipeline(models_to_compare,'V20X')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1e1271-e20b-49a3-bb2a-0e4b6fae7609",
   "metadata": {},
   "source": [
    "## Categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6e8d3-188f-410f-9cc8-ab42e700bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_condition        = 'clFr_change_is_significant & dl_change_is_significant & not oceanFr_change_is_significant & not si10Fr_change_is_significant'\n",
    "lake_ground_condition = 'clFr_change_is_significant & dl_change_is_significant & not oceanFr_change_is_significant & not cvhFr_change_is_significant & not cvlFr_change_is_significant'\n",
    "vegetation_condition  = 'cvhFr_change_is_significant & not clFr_change_is_significant'\n",
    "glacier_condition     = 'si10Fr_change_is_significant'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bdf081-fd7b-45af-b71b-b7a1b7780e0f",
   "metadata": {},
   "source": [
    "#### LAKES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3404123-82c4-4968-bf4e-91aecb00425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lake_v15 = df_V15.query(lake_condition)\n",
    "df_lake_v20 = df_V20.query(lake_condition)\n",
    "df_lake_v15X = df_V15X.query(lake_condition)\n",
    "df_lake_v20X = df_V20X.query(lake_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed68c4-3703-4b85-a2fc-cbd8dc845a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def histograms_and_deltas(df,df_reference,label):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
    "    #Histogram of the mean error\n",
    "    df_reference['mean_error'].hist(bins=100,ax=ax,label=\"V15\")\n",
    "    print(\"Mean = \", df_reference['mean_error'].mean())\n",
    "    print(\"Median = \", df_reference['mean_error'].median())\n",
    "\n",
    "    #Histogram of the mean error\n",
    "    df['mean_error'].hist(bins=100,ax=ax,label=label)\n",
    "    print(\"Mean = \", df['mean_error'].mean())\n",
    "    print(\"Median = \", df['mean_error'].median())\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(False)\n",
    "    \n",
    "    \n",
    "    print(\"delta = \",df['mean_error'].mean() - df_reference['mean_error'].mean())\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Noise plots\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
    "    #Histogram of the mean error\n",
    "    df_reference['variance'].hist(bins=100,ax=ax,label=\"V15\")\n",
    "    print(\"Mean = \", df_reference['variance'].mean())\n",
    "    print(\"Median = \", df_reference['variance'].median())\n",
    "\n",
    "    #Histogram of the mean error\n",
    "    df['variance'].hist(bins=100,ax=ax,label=label)\n",
    "    print(\"Mean = \", df['variance'].mean())\n",
    "    print(\"Median = \", df['variance'].median())\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(False)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def histograms_and_deltas_smart(df,df_reference,label):\n",
    "    \n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), dpi=300)\n",
    "    #Histogram of the mean error\n",
    "    df_reference['mean_error'].hist(bins=100,ax=ax,label=\"V15\")\n",
    "    print(\"Mean = \", df_reference['mean_error'].mean())\n",
    "    print(\"Median = \", df_reference['mean_error'].median())\n",
    "\n",
    "    #Histogram of the mean error\n",
    "    df['mean_error'].hist(bins=100,ax=ax,label=label)\n",
    "    print(\"Mean = \", df['mean_error'].mean())\n",
    "    print(\"Median = \", df['mean_error'].median())\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(False)\n",
    "    ax.set_xlabel('LST MAE [K]')\n",
    "    \n",
    "    \n",
    "#     V15_median =  df_reference['mean_error'].median()\n",
    "#     V20_median =  df['mean_error'].median()\n",
    "    \n",
    "#     ax.axvline(V15_median,linestyle='--',alpha=0.5,c='C0')\n",
    "#     ax.axvline(V20_median,linestyle='--',alpha=0.5,c=\"C1\")\n",
    "\n",
    "    plt.savefig(f\"images/categories_lakes_histogram.png\", bbox_inches=\"tight\",dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898792e2-ebd0-4ed4-a4f9-7f2b933ef71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms_and_deltas_smart(df_lake_v20,df_lake_v15,label=\"V20\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7a37c-239d-4eea-b07a-477331b2a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms_and_deltas(df_lake_v20,df_lake_v15,label=\"V20\")\n",
    "print('------------------------------')\n",
    "histograms_and_deltas(df_lake_v20X,df_lake_v15,label=\"V20X\")\n",
    "print('-------------------------------')\n",
    "histograms_and_deltas(df_lake_v15X,df_lake_v15,label=\"V15X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b5e75-3d51-4d94-85e1-ddef6963829c",
   "metadata": {},
   "source": [
    "#### Lake ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702ca00-2349-4510-89d6-73f81b4e4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lake_groundv15 = df_V15.query(lake_ground_condition)\n",
    "df_lake_groundv20 = df_V20.query(lake_ground_condition)\n",
    "df_lake_groundv15X = df_V15X.query(lake_ground_condition)\n",
    "df_lake_groundv20X = df_V20X.query(lake_ground_condition)\n",
    "\n",
    "\n",
    "histograms_and_deltas(df_lake_groundv20,df_lake_groundv15,label=\"V20\")\n",
    "print('------------------------------')\n",
    "histograms_and_deltas(df_lake_v20X,df_lake_groundv15,label=\"V20X\")\n",
    "print('-------------------------------')\n",
    "histograms_and_deltas(df_lake_groundv15X,df_lake_groundv15,label=\"V15X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187970a-2307-4713-81e4-3a9cbd7ce248",
   "metadata": {},
   "source": [
    "# Vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d033a544-0c0b-44bf-a85e-0210c6458ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veg_v15 = df_V15.query(vegetation_condition)\n",
    "df_veg_v20 = df_V20.query(vegetation_condition)\n",
    "df_veg_v15X = df_V15X.query(vegetation_condition)\n",
    "df_veg_v20X = df_V20X.query(vegetation_condition)\n",
    "\n",
    "\n",
    "histograms_and_deltas(df_veg_v20,df_veg_v15,label=\"V20\")\n",
    "print('------------------------------')\n",
    "histograms_and_deltas(df_veg_v20X,df_veg_v15,label=\"V20X\")\n",
    "print('-------------------------------')\n",
    "histograms_and_deltas(df_veg_v15X,df_veg_v15,label=\"V15X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421af903-45ce-4c6a-9c3f-6c0f6a2ebda5",
   "metadata": {},
   "source": [
    "# Glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3141ac7-7939-45f0-b3cc-d7257378a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glacier_v15 = df_V15.query(glacier_condition)\n",
    "df_glacier_v20 = df_V20.query(glacier_condition)\n",
    "df_glacier_v15X = df_V15X.query(glacier_condition)\n",
    "df_glacier_v20X = df_V20X.query(glacier_condition)\n",
    "\n",
    "\n",
    "histograms_and_deltas(df_glacier_v20,df_glacier_v15,label=\"V20\")\n",
    "print('------------------------------')\n",
    "histograms_and_deltas(df_glacier_v20X,df_glacier_v15,label=\"V20X\")\n",
    "print('-------------------------------')\n",
    "histograms_and_deltas(df_glacier_v15X,df_glacier_v15,label=\"V15X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e70379-9698-4f27-a14a-891fd2862d7f",
   "metadata": {},
   "source": [
    "#### Deep dive on individual bad points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08a881-0636-4d3d-8953-2e714b456899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lake = pd.concat([df_lake_v15,df_lake_v20,df_lake_v15X,df_lake_v20X])\n",
    "df_glacier = pd.concat([df_glacier_v15,df_glacier_v20,df_glacier_v15X,df_glacier_v20X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a380f081-c1c7-4bc0-b6b8-3959bb2c9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_natron = df_lake.query('latitude_ERA == -2.3887580539270044 & longitude_ERA == 36.0000')\n",
    "lake_natron_northern_edge =df_lake.query('latitude_ERA == -2.10772769472398 & longitude_ERA == 36.0000') \n",
    "lake_blanche =df_lake.query('latitude_ERA ==  -29.367671674745356 & longitude_ERA == 139.6875') \n",
    "salt_lake_city =df_lake.query('latitude_ERA ==  41.17094491970063 & longitude_ERA ==  -113.39999999999998') \n",
    "farah_province =df_lake.query('latitude_ERA ==  31.615914311651938 & longitude_ERA == 61.120000000000005') \n",
    "gujarat_province =df_lake.query('latitude_ERA ==  24.028095261448925 & longitude_ERA ==  69.0') \n",
    "toshka_lakes =df_lake.query('latitude_ERA ==  23.18500423251539 & longitude_ERA ==  30.900000000000006') \n",
    "all_northern_canada_points = df_lake.query('50.0 < latitude_ERA & -130 < longitude_ERA < -80')\n",
    "\n",
    "caspain_1 = df_lake.query('latitude_ERA ==  46.22948997297545 & longitude_ERA ==   49.125')\n",
    "caspain_2 = df_lake.query('latitude_ERA ==  46.22948997297545 & longitude_ERA ==    49.5')\n",
    "caspain_3 = df_lake.query('latitude_ERA ==  46.51052023808231 & longitude_ERA ==    49.5')\n",
    "caspain_4 = df_lake.query('latitude_ERA ==  47.072580762649004 & longitude_ERA ==    51.599999999999994')\n",
    "\n",
    "caspian_edge = pd.concat([caspain_1,caspain_2,caspain_3,caspain_4])\n",
    "\n",
    "bering_glacier = df_glacier.query('latitude_ERA == 60.280999861571715   & longitude_ERA ==    -143.4666666666667')\n",
    "juncal_glacier = df_glacier.query('latitude_ERA == -33.021065936911214   & longitude_ERA ==    -70.07999999999998')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3e77f-9f69-46c0-87f8-4ae859a6b3e3",
   "metadata": {},
   "source": [
    "### Lake natron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b38d5f-973d-4479-bf80-c8babf5132b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_cols = ['latitude_ERA', 'longitude_ERA','prediction_error_1','prediction_error_2','prediction_error_3','prediction_error_4','mean_error','variance','label']\n",
    "display(lake_natron[surface_cols])\n",
    "print(\"delta V20= \", lake_natron.query(\"label == 'V20'\")['mean_error'] - lake_natron.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", lake_natron.query(\"label == 'V20X'\")['mean_error'] - lake_natron.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", lake_natron.query(\"label == 'V15X'\")['mean_error'] - lake_natron.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583f9e2-b19e-4442-9d92-e77ea8b0ade2",
   "metadata": {},
   "source": [
    "### Lake natron, northern edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5882c0e9-07fd-47c8-8a0a-c54f72e74dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_cols = ['latitude_ERA', 'longitude_ERA','prediction_error_1','prediction_error_2','prediction_error_3','prediction_error_4','mean_error','variance','label']\n",
    "display(lake_natron_northern_edge[surface_cols])\n",
    "print(\"delta V20= \", lake_natron_northern_edge.query(\"label == 'V20'\")['mean_error'] - lake_natron_northern_edge.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", lake_natron_northern_edge.query(\"label == 'V20X'\")['mean_error'] - lake_natron_northern_edge.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", lake_natron_northern_edge.query(\"label == 'V15X'\")['mean_error'] - lake_natron_northern_edge.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d365af-b5e9-4aad-8dc9-ef133a48e8d5",
   "metadata": {},
   "source": [
    "### Lake Blanche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b40ff-ec5f-4faa-95c9-55eabe88d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lake_blanche[surface_cols])\n",
    "print(\"delta V20= \", lake_blanche.query(\"label == 'V20'\")['mean_error'] - lake_blanche.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", lake_blanche.query(\"label == 'V20X'\")['mean_error'] - lake_blanche.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", lake_blanche.query(\"label == 'V15X'\")['mean_error'] - lake_blanche.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a79343-2ecf-4020-bf8c-df0b17e6a004",
   "metadata": {},
   "source": [
    "### Salt lake city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d014f-2dc3-4aad-987f-7e7e19bdcd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(salt_lake_city[surface_cols])\n",
    "print(\"delta V20= \", salt_lake_city.query(\"label == 'V20'\")['mean_error'] - salt_lake_city.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", salt_lake_city.query(\"label == 'V20X'\")['mean_error'] - salt_lake_city.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", salt_lake_city.query(\"label == 'V15X'\")['mean_error'] - salt_lake_city.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ebc82-6963-4420-a1f6-3bf69f5c819e",
   "metadata": {},
   "source": [
    "### Farah province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f505fc32-33c6-4cfa-b186-6512048e8508",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(farah_province[surface_cols])\n",
    "print(\"delta V20= \", farah_province.query(\"label == 'V20'\")['mean_error'] - farah_province.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", farah_province.query(\"label == 'V20X'\")['mean_error'] - farah_province.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", farah_province.query(\"label == 'V15X'\")['mean_error'] - farah_province.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362fab8-3f1f-4721-aed7-c79e07639780",
   "metadata": {},
   "source": [
    "### Gujarat, India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3127e-c850-48c9-a94a-074ee35055ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(gujarat_province[surface_cols])\n",
    "print(\"delta V20= \", gujarat_province.query(\"label == 'V20'\")['mean_error'] - gujarat_province.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", gujarat_province.query(\"label == 'V20X'\")['mean_error'] - gujarat_province.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", gujarat_province.query(\"label == 'V15X'\")['mean_error'] - gujarat_province.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e03e2-278e-447b-afb3-8365e1efec47",
   "metadata": {},
   "source": [
    "### Toshka lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc0967-b46c-4dfe-9598-b4b93a3c84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(toshka_lakes[surface_cols])\n",
    "print(\"delta V20= \", toshka_lakes.query(\"label == 'V20'\")['mean_error'] - toshka_lakes.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", toshka_lakes.query(\"label == 'V20X'\")['mean_error'] - toshka_lakes.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", toshka_lakes.query(\"label == 'V15X'\")['mean_error'] - toshka_lakes.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d0312-5d8d-4dab-852d-8fa80518933d",
   "metadata": {},
   "source": [
    "### Northern Canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca60c5e-42bf-4f9f-a392-c7b7e18894f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display(all_northern_canada_points[surface_cols])\n",
    "\n",
    "\n",
    "\n",
    "histograms_and_deltas(all_northern_canada_points.query(\"label == 'V20'\"),all_northern_canada_points.query(\"label == 'V15'\"),label=\"V20\")\n",
    "print('------------------------------')\n",
    "histograms_and_deltas(all_northern_canada_points.query(\"label == 'V20X'\"),all_northern_canada_points.query(\"label == 'V15'\"),label=\"V20X\")\n",
    "print('-------------------------------')\n",
    "histograms_and_deltas(all_northern_canada_points.query(\"label == 'V15X'\"),all_northern_canada_points.query(\"label == 'V15'\"),label=\"V15X\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5026735-f9da-48b1-a846-b5fa9ce75636",
   "metadata": {},
   "source": [
    "### Caspian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da2d34-063c-4a60-a8fd-17c5412e97d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "caspian_edge\n",
    "\n",
    "\n",
    "\n",
    "display(caspian_edge[surface_cols])\n",
    "\n",
    "\n",
    "\n",
    "histograms_and_deltas(caspian_edge.query(\"label == 'V20'\"),caspian_edge.query(\"label == 'V15'\"),label=\"V20\")\n",
    "print('------------------------------')\n",
    "histograms_and_deltas(caspian_edge.query(\"label == 'V20X'\"),caspian_edge.query(\"label == 'V15'\"),label=\"V20X\")\n",
    "print('-------------------------------')\n",
    "histograms_and_deltas(caspian_edge.query(\"label == 'V15X'\"),caspian_edge.query(\"label == 'V15'\"),label=\"V15X\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f7a89-4d6b-4607-9651-8305113084de",
   "metadata": {},
   "source": [
    "### Bering glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbb911-4f1d-456e-bdae-a971cfbdf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bering_glacier[surface_cols])\n",
    "print(\"delta V20= \", bering_glacier.query(\"label == 'V20'\")['mean_error'] - bering_glacier.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", bering_glacier.query(\"label == 'V20X'\")['mean_error'] - bering_glacier.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", bering_glacier.query(\"label == 'V15X'\")['mean_error'] - bering_glacier.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc3101a-acd3-404a-827b-810387c23dbf",
   "metadata": {},
   "source": [
    "### Juncal glacier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5e472-d8ce-4981-803c-b76684fd9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(juncal_glacier[surface_cols])\n",
    "print(\"delta V20= \", juncal_glacier.query(\"label == 'V20'\")['mean_error'] - juncal_glacier.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V20X= \", juncal_glacier.query(\"label == 'V20X'\")['mean_error'] - juncal_glacier.query(\"label == 'V15'\")['mean_error'])\n",
    "print(\"delta V15X= \", juncal_glacier.query(\"label == 'V15X'\")['mean_error'] - juncal_glacier.query(\"label == 'V15'\")['mean_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc9ab8-2b72-4c0f-b2cf-e70f52c8cbfc",
   "metadata": {},
   "source": [
    "## Single grid points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983326a1-f574-4968-b67a-c9aee4786314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "singles = [lake_natron, \n",
    "           lake_natron_northern_edge, \n",
    "           lake_blanche,\n",
    "           salt_lake_city, \n",
    "           farah_province, \n",
    "           gujarat_province, \n",
    "           toshka_lakes, \n",
    "           bering_glacier, \n",
    "           juncal_glacier,\n",
    "          ]\n",
    "\n",
    "names = ['Lake Natron centre', \n",
    "           'Lake Natrom, north', \n",
    "           'Lake Blanche',\n",
    "           'Great Salt Lake Desert', \n",
    "           'Farah Province', \n",
    "           'Gujarat Province', \n",
    "           'Toshka Lakes', \n",
    "           'Bering Glacier', \n",
    "           'Juncal Glacier',\n",
    "          ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90ff8b-4924-4e4c-a8e6-8e4f3a25fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
    "\n",
    "\n",
    "x = np.arange(len(names))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(i,names[i])\n",
    "    df = singles[i]\n",
    "    xi=x[i]\n",
    "    \n",
    "    \n",
    "    y = df[['prediction_error_1','prediction_error_2','prediction_error_3','prediction_error_4']].to_numpy()\n",
    "    \n",
    "    V15  = y[0,:]\n",
    "    V20  = y[1,:]\n",
    "    V15X = y[2,:]\n",
    "    V20X = y[3,:]\n",
    "    \n",
    "    \n",
    "    for j in range(4):\n",
    "        ax.scatter(V15[j],xi,c=\"C0\",label=\"V15\")\n",
    "        ax.scatter(V20[j],xi,c=\"C1\",label=\"V20\")\n",
    "        #ax.scatter(V20X[j],xi,c=\"C2\",label=\"V20X\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# get the xticks, which are the numeric location of the ticks\n",
    "yticks = ax.get_yticks()\n",
    "\n",
    "# get the xticks and convert the values in the array to str type\n",
    "yticklabels = list(map(str, ax.get_yticks()))\n",
    "\n",
    "# update the string to be changed\n",
    "for k in range(len(names)):\n",
    "    \n",
    "    yticklabels[k+1] = names[k]\n",
    "    \n",
    "yticklabels[0] = ''\n",
    "yticklabels[-1] = ''\n",
    "\n",
    "\n",
    "# set the xticks and the labels\n",
    "_ = ax.set_yticks(yticks, yticklabels)\n",
    "    \n",
    "\n",
    "    \n",
    "ax.set_xlabel('LST MAE [K]')\n",
    "#plt.legend()\n",
    "\n",
    "colors = ['C0', 'C1']\n",
    "lines = [Line2D([0], [0], marker='o', color='w',markerfacecolor=c, markersize=7) for c in colors]\n",
    "labels = ['V15','V20']\n",
    "plt.legend(lines, labels)\n",
    "\n",
    "plt.savefig(f\"images/categories_v15_v20.png\", bbox_inches=\"tight\",dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab5f9b-f8e8-4f99-b697-22d79dcae953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), dpi=100)\n",
    "\n",
    "\n",
    "x = np.arange(len(names))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(names)):\n",
    "    print(i,names[i])\n",
    "    df = singles[i]\n",
    "    xi=x[i]\n",
    "    \n",
    "    \n",
    "    y = df[['prediction_error_1','prediction_error_2','prediction_error_3','prediction_error_4']].to_numpy()\n",
    "    \n",
    "    V15  = y[0,:]\n",
    "    V20  = y[1,:]\n",
    "    V15X = y[2,:]\n",
    "    V20X = y[3,:]\n",
    "    \n",
    "    \n",
    "    for j in range(4):\n",
    "        ax.scatter(V15[j],xi,c=\"C0\",label=\"V15\")\n",
    "        #ax.scatter(V20[j],xi,c=\"C1\",label=\"V20\")\n",
    "        ax.scatter(V20X[j],xi,c=\"C2\",label=\"V20X\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# get the xticks, which are the numeric location of the ticks\n",
    "yticks = ax.get_yticks()\n",
    "\n",
    "# get the xticks and convert the values in the array to str type\n",
    "yticklabels = list(map(str, ax.get_yticks()))\n",
    "\n",
    "# update the string to be changed\n",
    "for k in range(len(names)):\n",
    "    \n",
    "    yticklabels[k+1] = names[k]\n",
    "    \n",
    "yticklabels[0] = ''\n",
    "yticklabels[-1] = ''\n",
    "\n",
    "\n",
    "# set the xticks and the labels\n",
    "_ = ax.set_yticks(yticks, yticklabels)\n",
    "    \n",
    "\n",
    "    \n",
    "ax.set_xlabel('LST MAE [K]')\n",
    "#plt.legend()\n",
    "\n",
    "colors = ['C0', 'C2']\n",
    "lines = [Line2D([0], [0], marker='o', color='w',markerfacecolor=c, markersize=7) for c in colors]\n",
    "labels = ['V15','V20']\n",
    "plt.legend(lines, labels)\n",
    "\n",
    "plt.savefig(f\"images/categories_v15_v20X.png\", bbox_inches=\"tight\",dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65c46d-1be4-4ac2-becc-8698f4ba87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "toshka_lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600e491-100d-4d37-bc8a-e713d8cd08a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3214a-90d0-49bc-a649-91b3dd4f7043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
